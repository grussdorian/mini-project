{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6870365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22c1b800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))\n",
    "mnist = keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1699ffe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2269933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'keras.api._v2.keras.datasets.mnist' from '/Users/hardik/miniforge3/lib/python3.9/site-packages/keras/api/_v2/keras/datasets/mnist/__init__.py'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4426059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_temp,y_train),(x_test_temp,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68757d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb57b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.empty((60000, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f17ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.empty((10000, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77802a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:00<00:00, 66855.05it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 66988.50it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for index in tqdm( range( len(x_train_temp))):\n",
    "  x_train[index] =  np.pad(x_train_temp[index], [(0, 4), (0, 4)], mode='constant')\n",
    "\n",
    "for index in tqdm( range( len(x_test_temp))):\n",
    "  x_test[index] =  np.pad(x_test_temp[index], [(0, 4), (0, 4)], mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "608900c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n"
     ]
    }
   ],
   "source": [
    "d = x_test[0]\n",
    "print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c5d56cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16900ec70>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "452b289f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "  20/1875 [..............................] - ETA: 10s - loss: 24.1951 - accuracy: 0.1078"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-24 16:07:40.050485: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 9s 5ms/step - loss: 1.9975 - accuracy: 0.3586\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 1.1668 - accuracy: 0.5525\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.7528 - accuracy: 0.7569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x169060d00>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# x_train = keras.utils.normalize(x_train,axis=1)\n",
    "# x_test = keras.utils.normalize(x_test,axis=1)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(16,activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(16,activation=tf.nn.relu))\n",
    "# output\n",
    "model.add(keras.layers.Dense(10,activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train,y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "174f297c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1690600a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0], plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19ca7804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22/313 [=>............................] - ETA: 1s - loss: 0.6263 - accuracy: 0.8267"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-24 16:08:13.313711: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.5710 - accuracy: 0.8473\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3288843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5709882378578186 0.8473000526428223\n"
     ]
    }
   ],
   "source": [
    "print(val_loss, val_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c43c24d",
   "metadata": {},
   "source": [
    "## Model Quantization (Quantization aware training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91197521",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "q_aware_model = quantize_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d737d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer (QuantizeLay  (None, 32, 32)           3         \n",
      " er)                                                             \n",
      "                                                                 \n",
      " quant_flatten_1 (QuantizeWr  (None, 1024)             1         \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_dense_3 (QuantizeWrap  (None, 16)               16405     \n",
      " perV2)                                                          \n",
      "                                                                 \n",
      " quant_dense_4 (QuantizeWrap  (None, 16)               277       \n",
      " perV2)                                                          \n",
      "                                                                 \n",
      " quant_dense_5 (QuantizeWrap  (None, 10)               175       \n",
      " perV2)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,861\n",
      "Trainable params: 16,842\n",
      "Non-trainable params: 19\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "q_aware_model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "q_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b9e9689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "   1/1875 [..............................] - ETA: 10:57 - loss: 3.0463 - accuracy: 0.1562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-24 16:08:25.207855: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.7823 - accuracy: 0.7499\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.4140 - accuracy: 0.8853\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.3404 - accuracy: 0.9051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28a966fd0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_aware_model.fit(x_train,y_train, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02d3a67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14/313 [>.............................] - ETA: 2s - loss: 0.2774 - accuracy: 0.9196"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-24 16:09:40.221391: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3186 - accuracy: 0.9154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3185500502586365, 0.9154000282287598]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_aware_model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "878ec95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset():\n",
    "  for data in tf.data.Dataset.from_tensor_slices((x_train)).batch(1).take(100):\n",
    "    yield [tf.dtypes.cast(data, tf.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad5d4a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8  # or tf.uint8\n",
    "converter.inference_output_type = tf.uint8  # or tf.uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a15a2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-24 16:10:22.207564: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as flatten_1_layer_call_fn, flatten_1_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/gq/309vcw9507z_fp220k0ltqy80000gn/T/tmpe3cfviuv/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/gq/309vcw9507z_fp220k0ltqy80000gn/T/tmpe3cfviuv/assets\n",
      "/Users/hardik/miniforge3/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2022-12-24 16:10:24.507103: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2022-12-24 16:10:24.507117: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "2022-12-24 16:10:24.507521: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /var/folders/gq/309vcw9507z_fp220k0ltqy80000gn/T/tmpe3cfviuv\n",
      "2022-12-24 16:10:24.509112: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2022-12-24 16:10:24.509117: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /var/folders/gq/309vcw9507z_fp220k0ltqy80000gn/T/tmpe3cfviuv\n",
      "2022-12-24 16:10:24.515272: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-12-24 16:10:24.557320: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /var/folders/gq/309vcw9507z_fp220k0ltqy80000gn/T/tmpe3cfviuv\n",
      "2022-12-24 16:10:24.571736: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 64215 microseconds.\n",
      "2022-12-24 16:10:24.594074: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 3, output_inference_type: 3\n"
     ]
    }
   ],
   "source": [
    "tflite_quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ac115ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as flatten_1_layer_call_fn, flatten_1_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses, dense_4_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../data/quantized_mnist_new/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../data/quantized_mnist_new/assets\n"
     ]
    }
   ],
   "source": [
    "q_aware_model.save('../data/quantized_mnist_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7221c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"../data/quantized_mnist.tflite\", 'wb') as f:\n",
    "  f.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "29aeda84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Input details ==\n",
      "name: serving_default_flatten_1_input:0\n",
      "shape: [ 1 32 32]\n",
      "type: <class 'numpy.uint8'>\n",
      "\n",
      "== Output details ==\n",
      "name: StatefulPartitionedCall:0\n",
      "shape: [ 1 10]\n",
      "type: <class 'numpy.uint8'>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Create interpreter, allocate tensors\n",
    "'''\n",
    "tflite_interpreter = tf.lite.Interpreter(model_path='../data/quantized_mnist.tflite')\n",
    "tflite_interpreter.allocate_tensors()\n",
    "\n",
    "'''\n",
    "Check input/output details\n",
    "'''\n",
    "input_details = tflite_interpreter.get_input_details()\n",
    "output_details = tflite_interpreter.get_output_details()\n",
    "\n",
    "print(\"== Input details ==\")\n",
    "print(\"name:\", input_details[0]['name'])\n",
    "print(\"shape:\", input_details[0]['shape'])\n",
    "print(\"type:\", input_details[0]['dtype'])\n",
    "print(\"\\n== Output details ==\")\n",
    "print(\"name:\", output_details[0]['name'])\n",
    "print(\"shape:\", output_details[0]['shape'])\n",
    "print(\"type:\", output_details[0]['dtype'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42039c48",
   "metadata": {},
   "source": [
    "## Transpilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a085852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Transpiler import transpile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0866957",
   "metadata": {},
   "outputs": [],
   "source": [
    "transpile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671e2c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = keras.models.load_model('../data/hand_written_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a21f230",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = new_model.predict([x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d48d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 6\n",
    "plt.imshow(x_test[idx])\n",
    "print(np.argmax(predictions[idx]))\n",
    "plt.imshow(x_test[idx],plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eaf910",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fb098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_new,y_train_new),(x_test_new,y_test_new) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82537f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train_new[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07c7a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([x_test])\n",
    "# model.predict([x_train[0]])\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cb409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 10\n",
    "plt.imshow(x_test[index])\n",
    "print(np.argmax(predictions[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d360ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/digit_7.bin', 'wb') as f:\n",
    "    f.write(x_test_new[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seven = x_test_new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8954e996",
   "metadata": {},
   "outputs": [],
   "source": [
    "seven = np.pad(seven, [(0, 4), (0, 4)], mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e31da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seven.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff34001",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(seven)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5e4c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/digit_7.bin', 'wb') as f:\n",
    "    f.write(seven)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454b1ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cf9af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91e2f19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ece22298b122fc1ee12f20896455c63039877c7230fda1188a7151a9b90329c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
